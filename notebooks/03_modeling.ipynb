{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90de5850",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ecbd86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 03_modeling.ipynb\n",
    "# Modeling and Evaluation for Diabetes Binary Classification\n",
    "# Extended with Hyperparameter Tuning, Multiple Models, ANN, and Cost-Benefit Analysis\n",
    "# Integrated with preprocessing module\n",
    "# ============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src directory to Python path to import preprocessing module\n",
    "project_root = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "# Import preprocessing module\n",
    "try:\n",
    "    from dpp.preprocessing import get_preprocessed_data\n",
    "    PREPROCESSING_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    PREPROCESSING_AVAILABLE = False\n",
    "    print(f\"Warning: Could not import preprocessing module. Error: {e}\")\n",
    "    print(\"Using placeholder data for demonstration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1eb0c6",
   "metadata": {},
   "source": [
    "# Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0387f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOAD PREPROCESSED DATA\n",
      "================================================================================\n",
      "[preprocessing] Loading data from: C:\\Users\\Eyyub\\Desktop\\StackFuel\\PortfolioProjekt\\DPP-Stackfuel-Data-Science-Projekt\\data\\raw\\diabetes-health-indicators-dataset\\diabetes_binary_health_indicators_BRFSS2015.csv\n",
      "Training set size: 311,002\n",
      "Test set size: 45,895\n",
      "Number of features: 24\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 1. LOAD PREPROCESSED DATA\n",
    "# ============================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"LOAD PREPROCESSED DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if PREPROCESSING_AVAILABLE:\n",
    "    # Load preprocessed data from preprocessing module\n",
    "    try:\n",
    "        data = get_preprocessed_data()\n",
    "        features_train = data['features_train']\n",
    "        target_train = data['target_train']\n",
    "        features_test = data['features_test']\n",
    "        target_test = data['target_test']\n",
    "\n",
    "        print(f\"Training set size: {len(features_train):,}\")\n",
    "        print(f\"Test set size: {len(features_test):,}\")\n",
    "        print(f\"Number of features: {features_train.shape[1]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading preprocessed data: {e}\")\n",
    "        print(\"Using placeholder data for demonstration.\")\n",
    "        PREPROCESSING_AVAILABLE = False\n",
    "else:\n",
    "    print(\"Preprocessing module not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3198bf6c",
   "metadata": {},
   "source": [
    "# Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea7070d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL INITIALIZATION AND TRAINING\n",
      "================================================================================\n",
      "Training Random Forest...\n",
      "Training XGBoost...\n",
      "Training Logistic Regression...\n",
      "Training SVM...\n",
      "Training K-Nearest Neighbors...\n",
      "Training Decision Tree...\n",
      "Training Naive Bayes...\n",
      "Training Neural Network...\n",
      "All models trained successfully.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2. MODEL INITIALIZATION AND TRAINING\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL INITIALIZATION AND TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize multiple models with base parameters\n",
    "# Using LinearSVC with CalibratedClassifierCV for faster SVM training\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'SVM': CalibratedClassifierCV(\n",
    "        LinearSVC(random_state=42, max_iter=10000, dual=False),\n",
    "        cv=3\n",
    "    ),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Neural Network': MLPClassifier(random_state=42, max_iter=500)\n",
    "}\n",
    "\n",
    "# Train all models\n",
    "trained_models = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(features_train, target_train)\n",
    "    trained_models[name] = model\n",
    "\n",
    "print(\"All models trained successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpp (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
