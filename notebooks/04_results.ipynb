{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfdb633b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76e5d608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 04_results.py\n",
    "# Loads and visualizes results from 03_modeling.py\n",
    "# Includes model comparison, ROC/PR curves, confusion matrices, feature importance, and DCA\n",
    "# ============================================================================\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, precision_recall_curve, auc\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448712e6",
   "metadata": {},
   "source": [
    "# Load Models and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c78abd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOAD MODELS AND RESULTS\n",
      "================================================================================\n",
      "Loaded models: ['Random Forest', 'XGBoost', 'Logistic Regression', 'Neural Network', 'SVM', 'K-Nearest Neighbors', 'Decision Tree', 'Naive Bayes']\n",
      "Test labels shape: (45895,)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 1. LOAD MODELS AND RESULTS\n",
    "# ============================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"LOAD MODELS AND RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Festgelegter Pfad zu deinem models-Ordner\n",
    "models_dir = Path(r\"C:\\Users\\Eyyub\\Desktop\\StackFuel\\PortfolioProjekt\\DPP-Stackfuel-Data-Science-Projekt\\models\")\n",
    "\n",
    "# Lade die gespeicherten Modell-Ergebnisse\n",
    "model_results = joblib.load(models_dir / \"model_results.pkl\")\n",
    "\n",
    "# Lade die einzelnen Modelle (nach Name)\n",
    "models = {}\n",
    "for model_name in model_results.keys():\n",
    "    model_path = models_dir / f\"{model_name.replace(' ', '_')}_model.pkl\"\n",
    "    models[model_name] = joblib.load(model_path)\n",
    "\n",
    "# Lade die Test-Labels\n",
    "target_test = joblib.load(models_dir / \"target_test.pkl\")\n",
    "\n",
    "print(f\"Loaded models: {list(models.keys())}\")\n",
    "print(f\"Test labels shape: {target_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b72672",
   "metadata": {},
   "source": [
    "# Model Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3af777de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL COMPARISON TABLE\n",
      "================================================================================\n",
      "              Model      AUC  Precision   Recall       F1  Accuracy  Best Threshold\n",
      "            XGBoost 0.815416   0.370106 0.642399 0.469639  0.778102        0.260960\n",
      "Logistic Regression 0.808352   0.378504 0.602080 0.464804  0.787951        0.634490\n",
      "                SVM 0.808368   0.369580 0.624163 0.464261  0.779693        0.618986\n",
      "        Naive Bayes 0.762289   0.311205 0.684570 0.427891  0.720035        0.950891\n",
      "     Neural Network 0.769980   0.324482 0.609346 0.423465  0.746247        0.422415\n",
      "      Random Forest 0.763384   0.323888 0.597663 0.420109  0.747663        0.270000\n",
      "K-Nearest Neighbors 0.715296   0.278787 0.629862 0.386502  0.694193        0.600000\n",
      "      Decision Tree 0.592259   0.287119 0.336943 0.310042  0.770650        1.000000\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2. MODEL COMPARISON TABLE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON TABLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_data = []\n",
    "for name, res in model_results.items():\n",
    "    comparison_data.append({\n",
    "        \"Model\": name,\n",
    "        \"AUC\": res['auc'],\n",
    "        \"Precision\": res['precision'],\n",
    "        \"Recall\": res['recall'],\n",
    "        \"F1\": res['f1'],\n",
    "        \"Accuracy\": res['accuracy'],\n",
    "        \"Best Threshold\": res.get('best_threshold', 0.5)\n",
    "    })\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data).sort_values(\"F1\", ascending=False)\n",
    "print(df_comparison.to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpp (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
